{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changelog\n",
    "- 30 Sep 2019\n",
    "    - Creation\n",
    "    - Goal is to do MOBIL experimentation to demonstrate lane changes\n",
    "    - Idea flow\n",
    "        - Look at some videos to select a situation with enough spacing to make lane change\n",
    "        - Select a vehicle id that is on a slow lane\n",
    "        - Make it want to make a lange change by some selection of parameters\n",
    "- 2 Oct\n",
    "    - Defining in notebook copies of `MOBIL` and `Tim2DDriver` for debugging purposed\n",
    "    - Above did not work because methods being redefined not working (or something like that)\n",
    "    - Found that Maxime had a commit on June 18 fixing MOBIL.jl. Did a git pull \n",
    "    on `.julia/packages/dev/AutomotiveDrivingModels`\n",
    "    - Seems to change lane\n",
    "- 3 Oct\n",
    "    - Influence of stochastictity on the `ProportionalLaneTracker`\n",
    "    - trace the x and y positions of car\n",
    "- 10 Oct\n",
    "    - Function to get the lane id\n",
    "- 16 Oct\n",
    "    - Back to working in this notebook now that upstream dependencies in `AutomotiveDrivingModels.jl`\n",
    "    have solidified\n",
    "    - `uncertain_IDM.jl` is a new driver model that has been defined in `AutomotiveDrivingModels/src/behaviors`\n",
    "    - Global things defined at top of notebook to step away from dictionary based particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# using packages\n",
    "using NGSIM\n",
    "using AutomotiveDrivingModels\n",
    "using AutoViz\n",
    "using Reel\n",
    "using Distributions\n",
    "using Random\n",
    "using PGFPlots\n",
    "using LinearAlgebra # To make the MvNormal covariance work maybe\n",
    "using JLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# define global things: timestep, roadway, traj\n",
    "const TIMESTEP = 0.1;\n",
    "const V_DES = 1; const SIGMA_IDM = 2; const T_HEADWAY = 3; const S_MIN=4; \n",
    "const POLITENESS = 5;const ADV_TH = 6;const SENSOR_SIGMA = 7;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# overlays: IDOverlay. my_overlay\n",
    "\"\"\"\n",
    "    IDOverlay\n",
    "Display the ID on top of each entity in a scene.\n",
    "# Fields\n",
    "- `color::Colorant`\n",
    "- `font_size::Int64`\n",
    "\"\"\"\n",
    "mutable struct IDOverlay <: SceneOverlay\n",
    "    color::Colorant\n",
    "    font_size::Int\n",
    "end\n",
    "\n",
    "function AutoViz.render!(rendermodel::RenderModel, overlay::IDOverlay, scene::Scene, \n",
    "                            env::E) where E\n",
    "    font_size = overlay.font_size\n",
    "    for veh in scene\n",
    "        add_instruction!(rendermodel, render_text, (\"$(veh.id)\", veh.state.posG.x, \n",
    "                        veh.state.posG.y, font_size, overlay.color), incameraframe=true)\n",
    "    end\n",
    "    return rendermodel\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    my_overlay\n",
    "Overlaying hallucinated trajectory on the ground truth\n",
    "# Fields\n",
    "- `color::Colorant`\n",
    "- `scene::Scene`\n",
    "\"\"\"\n",
    "struct my_overlay <: SceneOverlay\n",
    "    scene::Scene\n",
    "    color # Needs to be of form colorant\"Colorname\"\n",
    "end\n",
    "\n",
    "function AutoViz.render!(rendermodel::RenderModel,overlay::my_overlay, \n",
    "        scene::Scene, roadway::Roadway)\n",
    "    AutoViz.render!(rendermodel,overlay.scene,car_color = overlay.color)\n",
    "    return rendermodel\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     8,
     23
    ]
   },
   "outputs": [],
   "source": [
    "# functions: get lane id, lane change probability\n",
    "\"\"\"\n",
    "    function get_lane_id(scene,car_id)\n",
    "# Examples\n",
    "```julia\n",
    "get_lane_id(scene,1)\n",
    "```\n",
    "\"\"\"\n",
    "function get_lane_id(scene,car_id)\n",
    "    veh = scene[findfirst(car_id,scene)]\n",
    "    return veh.state.posF.roadind.tag.lane\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    function get_lane_change_prob(start_scene,particle;car_id=-1,num_samplings=10)\n",
    "- Probability of lane changing start from `start_scene`\n",
    "- hallucinating using `particle` for `car_id` using `num_samplings` hallucinations\n",
    "\n",
    "# Examples\n",
    "```julia\n",
    "lp = get_lane_change_prob(scene,particle,car_id = 1)\n",
    "```\n",
    "\"\"\"\n",
    "function get_lane_change_prob(start_scene,particle;car_id=-1,num_samplings=10)\n",
    "    if car_id==-1 @show \"Please give valid car_id\" end\n",
    "    start_lane = get_lane_id(start_scene,car_id)\n",
    "    changed_count = 0; unchanged_count = 0\n",
    "    for i in 1:num_samplings\n",
    "        hpos,hlane = hallucinate_a_step(start_scene,particle,car_id=car_id)\n",
    "        if hlane == start_lane\n",
    "            unchanged_count += 1\n",
    "\telse\n",
    "\t    changed_count += 1\n",
    "\tend\n",
    "    end\n",
    "    return changed_count/num_samplings\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# function: generate roadway and place cars\n",
    "\"\"\"\n",
    "    function init_place_cars(lane_place_array;road_length = 1000.0)\n",
    "- Place cars on a straight roadway of `road_length` according to elems in `lane_place_array`\n",
    "\n",
    "# Examples\n",
    "```julia\n",
    "pos_vel_array_1 = [(200.,30.),(215.,0.),(220.,0.)]\n",
    "pos_vel_array_2 = [(200.,0.),(215.,0.),(220.,20.)]\n",
    "pos_vel_array_3 = [(215.,0.),(225.,10.),(230.,0.)]\n",
    "lane_place_array = [pos_vel_array_1,pos_vel_array_2,pos_vel_array_3]\n",
    "scene,roadway = init_place_cars(lane_place_array)\n",
    "```\n",
    "\"\"\"\n",
    "function init_place_cars(lane_place_array;road_length = 1000.0)\n",
    "    num_lanes = length(lane_place_array)\n",
    "    roadway = gen_straight_roadway(num_lanes,road_length)\n",
    "    scene = Scene()\n",
    "\n",
    "    id = 1\n",
    "    for i in 1:num_lanes\n",
    "        for j in 1:length(lane_place_array[i])\n",
    "            veh_state = VehicleState(Frenet(roadway[LaneTag(1,i)],\n",
    "                    lane_place_array[i][j][1]),roadway,\n",
    "                lane_place_array[i][j][2])\n",
    "            veh = Vehicle(veh_state,VehicleDef(),id)\n",
    "            push!(scene,veh)\n",
    "            id+=1\n",
    "        end\n",
    "    end\n",
    "    return scene,roadway\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# function: make video from scene list, make video with overlay from additional scenelist\n",
    "\"\"\"\n",
    "    function scenelist2video\n",
    "- Make video from a list of scenes\n",
    "\n",
    "# Examples\n",
    "```julia\n",
    "scenelist2video(scene_list,roadway=roadway)\n",
    "```\n",
    "\"\"\"\n",
    "function scenelist2video(scene_list;\n",
    "    filename = \"media/mobil/scene_to_video.mp4\")\n",
    "    frames = Frames(MIME(\"image/png\"),fps = 10)\n",
    "    \n",
    "    # Loop over list of scenes and convert to video\n",
    "    for i in 1:length(scene_list)\n",
    "        scene_visual = render(scene_list[i],ROADWAY,\n",
    "        [IDOverlay(colorant\"white\",12)],\n",
    "#         cam=FitToContentCamera(0.),\n",
    "        cam = CarFollowCamera(1)\n",
    "        )\n",
    "        push!(frames,scene_visual)\n",
    "    end\n",
    "    print(\"Making video filename: $(filename)\\n\")\n",
    "    write(filename,frames)\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    function scenelist2video\n",
    "- Make video from two different list of scenes overlaying `scene_list_2` on top of `scene_list_1`\n",
    "\n",
    "# Examples\n",
    "```julia\n",
    "scenelist2video(scene_list,roadway=roadway)\n",
    "```\n",
    "\"\"\"\n",
    "function multiple_scenelist2video(scene_list_1,scene_list_2;\n",
    "    filename = \"media/mobil/multiple_scene_to_video.mp4\")\n",
    "    frames = Frames(MIME(\"image/png\"),fps = 10)\n",
    "    @assert length(scene_list_1) == length(scene_list_2)\n",
    "    # Loop over list of scenes and convert to video\n",
    "    for i in 1:length(scene_list)\n",
    "        other_overlay = my_overlay(scene_list_2[i],colorant\"blue\")\n",
    "        scene_visual = render(scene_list[i],ROADWAY,\n",
    "        [IDOverlay(colorant\"white\",12),other_overlay],\n",
    "#         cam=FitToContentCamera(0.),\n",
    "        cam = CarFollowCamera(1)\n",
    "        )\n",
    "        push!(frames,scene_visual)\n",
    "    end\n",
    "    print(\"Making video filename: $(filename)\\n\")\n",
    "    write(filename,frames)\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "- Make a video only taking every 5 timesteps into account from `scene_list`\n",
    "\"\"\"\n",
    "function scenelist2video_quantized(scene_list;\n",
    "    filename = \"media/mobil/scene_to_video.mp4\")\n",
    "    frames = Frames(MIME(\"image/png\"),fps = 5)\n",
    "    \n",
    "    # Loop over list of scenes and convert to video\n",
    "    for i in 1:length(scene_list)\n",
    "\tif i%5 == 0\n",
    "\t\tscene_visual = render(scene_list[i],ROADWAY,\n",
    "\t\t[IDOverlay(colorant\"white\",12),TextOverlay(text=[\"frame=$(i)\"],font_size=12)],\n",
    "\t#         cam=FitToContentCamera(0.),\n",
    "\t\tcam = CarFollowCamera(1)\n",
    "\t\t)\n",
    "\t\tpush!(frames,scene_visual)\n",
    "\tend\n",
    "    end\n",
    "    print(\"Making video filename: $(filename)\\n\")\n",
    "    write(filename,frames)\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     10
    ]
   },
   "outputs": [],
   "source": [
    "# functions: plot things using pgfplots\n",
    "\"\"\"\n",
    "    function scenelist2ytrace(scene_list;car_id=-1)\n",
    "- Make a y position trace from a list of scenes\n",
    "\n",
    "# Examples\n",
    "```julia\n",
    "scenelist2ytrace(scene_list,car_id=1)\n",
    "```\n",
    "\"\"\"\n",
    "function scenelist2ytrace(scene_list;car_id=-1)\n",
    "    if car_id == -1 print(\"Please provide a valid car_id\\n\") end\n",
    "\n",
    "    p = PGFPlots.Plots.Scatter(collect(1:length(scene_list)),\n",
    "        [scene[findfirst(car_id,scene)].state.posG.y for scene in scene_list],legendentry=\"y trace\")\n",
    "    return p\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# function: hallucinate scene list\n",
    "\"\"\"\n",
    "    function get_hallucination_scenes\n",
    "- Hallucinate starting from `start_step` for `nsteps` using `models` and return a list of scenes\n",
    "- Used by `plot_carwise_pos_vel` to assess position and velocity traces against ground truth\n",
    "\n",
    "# Returns\n",
    "- `halluc_scenes_list`: List containing the scenes starting with the ground truth scene at `start_step`\n",
    "\n",
    "# Examples\n",
    "```julia\n",
    "scene_list = get_hallucination_scenes(start_scene,nsteps=100,models=models,\n",
    "roadway=roadway);\n",
    "```\n",
    "\"\"\"\n",
    "function get_hallucination_scenes(start_scene;nsteps,models,start_step=1,\n",
    "        id_list=[],verbosity = false)\n",
    "        # Setting up\n",
    "    scene_halluc = start_scene\n",
    "    halluc_scenes_list = []\n",
    "#     scene_halluc = get_scene(start_step,traj) # Frame to start hallucination from\n",
    "#     push!(halluc_scenes_list,deepcopy(scene_halluc))\n",
    "    \n",
    "    for (i,t) in enumerate(start_step:start_step+nsteps-1)\n",
    "        \n",
    "#         if !isempty(id_list) keep_vehicle_subset!(scene_halluc,id_list) end\n",
    "        \n",
    "        actions = Array{Any}(undef,length(scene_halluc))\n",
    "\n",
    "            # Propagation of scene forward\n",
    "        get_actions!(actions,scene_halluc,ROADWAY,models)\n",
    "\n",
    "        tick!(scene_halluc,ROADWAY,actions,TIMESTEP)\n",
    "        \n",
    "        push!(halluc_scenes_list,deepcopy(scene_halluc))\n",
    "    end \n",
    "    return halluc_scenes_list\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# function: hallucinate_a_step\n",
    "function hallucinate_a_step(scene_input,particle;car_id=-1)\n",
    "    if car_id==-1 @show \"Please give a valid car_id\" end\n",
    "\n",
    "    scene = deepcopy(scene_input)\n",
    "    models = Dict{Int64,DriverModel}()\n",
    "\n",
    "    for veh in scene\n",
    "        if veh.id == car_id\n",
    "            models[veh.id] = Tim2DDriver(TIMESTEP,\n",
    "                                    mlane=MOBIL(TIMESTEP,politeness=particle[POLITENESS],\n",
    "                                                advantage_threshold=particle[ADV_TH],\n",
    "                                                mlon=uncertain_IDM(sigma_sensor=particle[SENSOR_SIGMA])\n",
    "                                    ),\n",
    "                                    mlon = IntelligentDriverModel(v_des=particle[V_DES],σ=particle[SIGMA_IDM],\n",
    "                                            T=particle[T_HEADWAY],s_min=particle[S_MIN]\n",
    "                                    )\n",
    "                            )\n",
    "        else\n",
    "            models[veh.id] = IntelligentDriverModel(v_des=50.)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    actions = Array{Any}(undef,length(scene))\n",
    "    get_actions!(actions,scene,ROADWAY,models)\n",
    "    tick!(scene,ROADWAY,actions,TIMESTEP)\n",
    "\n",
    "    halluc_state = scene.entities[findfirst(car_id,scene)].state\n",
    "    halluc_pos = halluc_state.posF.s\n",
    "    halluc_lane = get_lane_id(scene,car_id)\n",
    "\n",
    "    return halluc_pos,halluc_lane\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# script: Place cars on a straight roadway and generate driving video\n",
    "pos_vel_array_1 = [(200.,30.),(250.,0.)]\n",
    "pos_vel_array_2 = [(250.,10.)]\n",
    "pos_vel_array_3 = [(215.,0.),(225.,10.),(230.,0.)]\n",
    "lane_place_array = [pos_vel_array_1,pos_vel_array_2]\n",
    "scene,roadway = init_place_cars(lane_place_array)\n",
    "\n",
    "models = Dict{Int64,DriverModel}()\n",
    "for veh in scene\n",
    "#     print(\"veh.id = $(veh.id)\\n\")\n",
    "#     models[veh.id] = LatLonSeparableDriver(ProportionalLaneTracker(),IntelligentDriverModel())\n",
    "    models[veh.id] = IntelligentDriverModel()\n",
    "end\n",
    "politeness = 0.\n",
    "models[1] = Tim2DDriver(timestep_ngsim,mlane=MOBIL(timestep_ngsim,politeness=politeness))\n",
    "models[2] = IntelligentDriverModel(v_des=15.)\n",
    "\n",
    "scene_list = get_hallucination_scenes(scene,nsteps=100,models=models,roadway=roadway);\n",
    "#scenelist2video(scene_list,roadway=roadway,filename=\"media/mobil/polite_$(politeness)_lane_change.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# plot: Lane id and y position overlap together to assess quantization of time\n",
    "numsteps = 40\n",
    "p1 = PGFPlots.Plots.Scatter(collect(1:numsteps),\n",
    "    [get_lane_id(scene,1) for scene in scene_list[1:numsteps]],legendentry=\"veh 1\")\n",
    "p2 = PGFPlots.Plots.Scatter(collect(1:numsteps),\n",
    "    [get_lane_id(scene,2) for scene in scene_list[1:numsteps]],legendentry=\"veh 2\")\n",
    "p3 = PGFPlots.Plots.Scatter(collect(1:numsteps),\n",
    "    [get_lane_id(scene,3) for scene in scene_list[1:numsteps]],legendentry=\"veh 3\")\n",
    "py1 = PGFPlots.Plots.Scatter(collect(1:numsteps),\n",
    "    [scene[1].state.posG.y for scene in scene_list[1:numsteps]],legendentry = \"y pos\")\n",
    "PGFPlots.Axis([p1,py1],xlabel=\"timestep\",ylabel=\"Lane number/y position\",legendPos=\"outer north east\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment: run starting from a scene to see what happens\n",
    "start_scene = deepcopy(scene_list[10])\n",
    "scene_list_quantization = get_hallucination_scenes(start_scene; nsteps=90,models=models,roadway=roadway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Compare two politeness values in one video by overlaying\n",
    "pos_vel_array_1 = [(200.,30.),(250.,0.)]\n",
    "pos_vel_array_2 = [(250.,10.)]\n",
    "pos_vel_array_3 = [(215.,0.),(225.,10.),(230.,0.)]\n",
    "lane_place_array = [pos_vel_array_1,pos_vel_array_2]\n",
    "scene,roadway = init_place_cars(lane_place_array)\n",
    "start_scene = deepcopy(scene)\n",
    "models_1 = Dict{Int64,DriverModel}()\n",
    "models_2 = Dict{Int64,DriverModel}()\n",
    "for veh in scene\n",
    "    models_1[veh.id] = IntelligentDriverModel()\n",
    "    models_2[veh.id] = IntelligentDriverModel()\n",
    "end\n",
    "politeness = 0.\n",
    "models_1[1] = Tim2DDriver(timestep_ngsim,mlane=MOBIL(timestep_ngsim,politeness=politeness))\n",
    "models_1[2] = IntelligentDriverModel(v_des=15.)\n",
    "\n",
    "scene_list_1 = get_hallucination_scenes(scene,nsteps=100,models=models_1,roadway=roadway)\n",
    "\n",
    "politeness = 1.\n",
    "models_2[1] = Tim2DDriver(timestep_ngsim,mlane=MOBIL(timestep_ngsim,politeness=politeness))\n",
    "models_2[2] = IntelligentDriverModel(v_des=15.)\n",
    "\n",
    "scene_list_2 = get_hallucination_scenes(start_scene,nsteps=100,models=models_2,roadway=roadway)\n",
    "multiple_scenelist2video(scene_list_1,scene_list_2,roadway=roadway,\n",
    "    filename=\"media/mobil/compare_politeness.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Compare two advantage_threshold values in one video by overlaying\n",
    "pos_vel_array_1 = [(200.,30.),(250.,0.)]\n",
    "pos_vel_array_2 = [(250.,10.)]\n",
    "pos_vel_array_3 = [(215.,0.),(225.,10.),(230.,0.)]\n",
    "lane_place_array = [pos_vel_array_1,pos_vel_array_2]\n",
    "scene,roadway = init_place_cars(lane_place_array)\n",
    "start_scene = deepcopy(scene)\n",
    "models_1 = Dict{Int64,DriverModel}()\n",
    "models_2 = Dict{Int64,DriverModel}()\n",
    "for veh in scene\n",
    "    models_1[veh.id] = IntelligentDriverModel()\n",
    "    models_2[veh.id] = IntelligentDriverModel()\n",
    "end\n",
    "politeness = 0.\n",
    "a_th = 0.\n",
    "models_1[1] = Tim2DDriver(timestep_ngsim,\n",
    "    mlane=MOBIL(timestep_ngsim,politeness=politeness,advantage_threshold=a_th))\n",
    "models_1[2] = IntelligentDriverModel(v_des=15.)\n",
    "\n",
    "scene_list_1 = get_hallucination_scenes(scene,nsteps=100,models=models_1,roadway=roadway)\n",
    "\n",
    "politeness = 0.\n",
    "a_th = 1.\n",
    "models_2[1] = Tim2DDriver(timestep_ngsim,\n",
    "    mlane=MOBIL(timestep_ngsim,politeness=politeness,advantage_threshold=a_th))\n",
    "models_2[2] = IntelligentDriverModel(v_des=15.)\n",
    "\n",
    "scene_list_2 = get_hallucination_scenes(start_scene,nsteps=100,models=models_2,roadway=roadway)\n",
    "multiple_scenelist2video(scene_list_1,scene_list_2,roadway=roadway,\n",
    "    filename=\"media/mobil/compare_adv_blueHighThreshold_p_0.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Influence of stochasticity on lateral driving\n",
    "seed=3;\n",
    "Random.seed!(seed) # To control the stochasticity in ProportionalLaneTracker\n",
    "\n",
    "pos_vel_array_1 = [(200.,30.),(250.,0.)]\n",
    "pos_vel_array_2 = [(250.,10.)]\n",
    "pos_vel_array_3 = [(215.,0.),(225.,10.),(230.,0.)]\n",
    "lane_place_array = [pos_vel_array_1,pos_vel_array_2]\n",
    "scene,roadway = init_place_cars(lane_place_array)\n",
    "start_scene = deepcopy(scene)\n",
    "models_1 = Dict{Int64,DriverModel}()\n",
    "models_2 = Dict{Int64,DriverModel}()\n",
    "for veh in scene\n",
    "    models_1[veh.id] = IntelligentDriverModel()\n",
    "    models_2[veh.id] = IntelligentDriverModel()\n",
    "end\n",
    "models_1[1] = Tim2DDriver(timestep_ngsim,\n",
    "    mlane=MOBIL(timestep_ngsim),\n",
    "    mlat=ProportionalLaneTracker()\n",
    ")\n",
    "models_1[2] = IntelligentDriverModel(v_des=15.)\n",
    "\n",
    "scene_list_1 = get_hallucination_scenes(scene,nsteps=100,models=models_1,roadway=roadway)\n",
    "\n",
    "sigma_lat = 10.\n",
    "models_2[1] = Tim2DDriver(timestep_ngsim,\n",
    "    mlane=MOBIL(timestep_ngsim),\n",
    "    mlat=ProportionalLaneTracker(σ=sigma_lat)\n",
    ")\n",
    "models_2[2] = IntelligentDriverModel(v_des=15.)\n",
    "\n",
    "scene_list_2 = get_hallucination_scenes(start_scene,nsteps=100,models=models_2,roadway=roadway)\n",
    "multiple_scenelist2video(scene_list_1,scene_list_2,roadway=roadway,\n",
    "    filename=\"media/mobil/lateral_blueIsStochastic_$(seed)_seed_sigmaLat_$(sigma_lat).mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Let's plot the x,y trace of car 1\n",
    "x = fill(0.,length(scene_list_1),2)\n",
    "y = fill(0.,length(scene_list_1),2)\n",
    "for (i,scene) in enumerate(scene_list_1)\n",
    "    x[i,1] = scene[findfirst(1,scene)].state.posG.x\n",
    "    y[i,1] = scene[findfirst(1,scene)].state.posG.y\n",
    "    x[i,2] = scene[findfirst(2,scene)].state.posG.x\n",
    "    y[i,2] = scene[findfirst(2,scene)].state.posG.y\n",
    "end\n",
    "car1 = PGFPlots.Plots.Scatter(x[:,1],y[:,1],legendentry=\"follower\")\n",
    "car2 = PGFPlots.Plots.Scatter(x[:,2],y[:,2],legendentry=\"leader\")\n",
    "laneboundary0 = PGFPlots.Plots.Linear(x[:,1],fill(-1.5,length(scene_list_1)),\n",
    "    style=\"black,ultra thick\",legendentry=\"lane edge\")\n",
    "laneboundary1 = PGFPlots.Plots.Linear(x[:,1],fill(1.5,length(scene_list_1)),style=\"black,ultra thick\")\n",
    "laneboundary2 = PGFPlots.Plots.Linear(x[:,1],fill(4.5,length(scene_list_1)),style=\"black,ultra thick\")\n",
    "\n",
    "mystyle = \"{draw=none,at={(0.5,-0.2)},anchor=north,legend columns=3,\n",
    "          /tikz/every even column/.append style={column sep=0.2cm}}\"\n",
    "PGFPlots.Axis([car1,car2,laneboundary0,laneboundary1,laneboundary2],xlabel=\"x\",ylabel=\"y\",legendStyle=mystyle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bivariate normal to experiment with the noise in proportional lane tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = MvNormal([0.,0.],[1. 0.;0. 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf(d,[0.5,-0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets think of a hybrid discrete and continuous distribution\n",
    "b = Bernoulli(0.3)\n",
    "rand(b,50)\n",
    "pdf(b,0)\n",
    "d = Normal(0,1)\n",
    "pdf(b,0)*pdf(d,0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### implement functions for hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- Hallucinate using a particle, return its likelihood\n",
    "\"\"\"\n",
    "particle = [politeness, sigma_lat]\n",
    "model = Tim2DDriver(timestep_ngsim,mlane=MOBIL(timestep_ngsim,politeness=particle[1]),\n",
    "    mlat=ProportionalLaneTracker(σ=particle[2])\n",
    ")\n",
    "get_actions!\n",
    "tick!\n",
    "\n",
    "compute the likelihood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function overlay_jld_scenelists(num_exps)\n",
    "    horizon = 100\n",
    "    list_of_plots = PGFPlots.Plot[]\n",
    "    for i in 1:num_exps\n",
    "        scene_list = JLD.load(\"media/mobil/$(i).jld\",\"scene_list\")\n",
    "        p = PGFPlots.Plots.Scatter(collect(1:horizon),\n",
    "            [scene[1].state.posG.y for scene in scene_list[1:horizon]],\n",
    "            legendentry = \"scenario $(i)\")\n",
    "        push!(list_of_plots,p)\n",
    "    end\n",
    "    pa = PGFPlots.Axis(list_of_plots,xlabel=\"timestep\",ylabel=\"y pos\",\n",
    "        legendPos=\"outer north east\")\n",
    "    display(pa)\n",
    "    PGFPlots.save(\"media/mobil/sensor_noise_impact.pdf\",pa)\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_jld_scenelists(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
